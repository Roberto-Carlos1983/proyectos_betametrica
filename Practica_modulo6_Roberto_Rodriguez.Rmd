---
title: "Practica_modulo6_Roberto_Rodriguez"
author: "Roberto_Rodriguez"
date: "`r Sys.Date()`"
output: github_document
---

```{r librerias, include=FALSE, warning=FALSE}
library(foreign)
library(dplyr)
library(caret)
library(ROCR)
library(e1071)
library(pROC)
library(reshape2)
library(ROSE)
```

# SECCION A

## Carga de datos

```{r carga_base, message=FALSE}
datos <- read.spss("D:\\Ciencia de datos\\Modulo 5\\MACHINE LEARNING 1\\ENCUESTA NACIDOS VIVOS\\ENV_2017.sav",
                   use.value.labels = F,
                   to.data.frame = T)
head(datos,3)
```

## Filtros, transformaciones y categorizaciones

Se filtraran los casos en lo que la provincia de nacimiento es MANABI, además se seleccionarán las variables para el modelo, se filtraran las observaciones que no tienen información y categorizaran las variables.

```{r filtros}
datos$prov_nac <- as.numeric(as.character(datos$prov_nac))

nuevadata <- datos %>%
  filter(prov_nac==13) %>%
  select(peso,talla,sem_gest,sexo,edad_mad,sabe_leer,con_pren) %>%
  filter(peso!=99,talla!=99,sem_gest!=99,edad_mad!=99,sabe_leer!=9,con_pren!=99) %>%
  mutate(peso=if_else(peso>2500,1,0),
         sexo=if_else(sexo==1,0,1),
         sabe_leer=if_else(sabe_leer==1,1,0),
         con_pren=if_else(con_pren>=7,1,0),
         edad2=edad_mad^2)

nuevadata$peso <- factor(nuevadata$peso)

head(nuevadata, 5)

nuevadata <- nuevadata %>%
  mutate(peso=recode_factor(peso,
                            `0`="no.adecuado",
                            `1`="adecuado"))

table(nuevadata$peso)

count(nuevadata)
```

### Seleccion de muestra de entrenamiento

Se seleccionara el 10% de la observaciones como muestra de entrenamiento.

```{r muestra_entre}
set.seed(1234)

entrenamiento <- createDataPartition(nuevadata$peso,
                                     p=0.10,list=F)
```

A continuacion, se estimara un SVM con cross-validation, con todas las variables seleccionadas.

```{r modelo_SVM}
modelo.tuneado <-  tune(svm,
                        peso ~.,
                        data=nuevadata[entrenamiento,],
                        ranges = list(cost=c(0.001,0.01,0.1,1,5,10,50)),
                        kernel="linear",
                        scale=T,
                        probability=TRUE)

summary(modelo.tuneado)
```

## Performance del modelo SVM

```{r performance_SVM, echo=FALSE}
ggplot(data=modelo.tuneado$performances,
       aes(x=cost,y=error))+
  geom_line()+
  geom_point()+
  labs(title="Error de validacion vs hipeparametro C")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))
```

El mejor modelo a partir del cross-validation es el que tiene un cost de 0.1 ya que con este costo, se minimiza el error.

## Mejor modelo SVM

El mejor modelo SVM se guardara en un objeto.

```{r best_modelSVM}
mejor.modelo <- modelo.tuneado$best.model
summary(mejor.modelo)
```

# SECCION B

## Evaluacion del modelo

### Matriz de clasificacion

```{r matriz_clasificacion, echo=FALSE}
ajustados.mejor.modelo <- predict(mejor.modelo,
                                  nuevadata[entrenamiento,],
                                  type="prob",
                                  probability = T)

confusionMatrix(ajustados.mejor.modelo,
                nuevadata$peso[entrenamiento],
                positive = levels(nuevadata$peso)[2])
```

El accuracy es alto, la sensitividad es alta, sin embargo, la especificidad tiene un valor bajo, lo que podria estar denotando un problema de desbalanceo de la muestra. Por otra parte, las tasas de acierto positivos es alta y podria decirse lo mismo de la tasa de aciertos negativa, que es de 0.75.

### Curva ROC

```{r curvaROC, echo=FALSE}
pred <- prediction(attr(ajustados.mejor.modelo,
                        "probabilities")[,2],
                   nuevadata$peso[entrenamiento])

perf <- performance(pred,"tpr","fpr")
plot(perf,colorize=T,lty=3)
abline(0,1,col="black")
```

La curva se aleja de la linea de 45 grados, lo que indica que el modelo podria estar discriminando correctamente los datos.

### Area bajo la curva

```{r AUC, echo=FALSE}
aucmodelo1 <- performance(pred,measure = "auc")
aucmodelo1 <- aucmodelo1@y.values[[1]]
aucmodelo1
```

El valor de 0.85 es alto, indica que esta discriminando correctamente.

## Punto de corte optimo

### Enfoque de maximizacion de sensitividad-especificidad

```{r puntocorteoptimo_senesp, warning=FALSE, echo=FALSE}
perf1 <- performance(pred, "sens","spec") 
sen <- slot(perf1,"y.values"[[1]])
esp <- slot(perf1,"x.values"[[1]])
alf <- slot(perf1,"alpha.values"[[1]])

mat <- data.frame(alf,sen,esp)

names(mat)[1] <- "alf"
names(mat)[2] <- "sen"
names(mat)[3] <- "esp"

m <- melt(mat,id=c("alf"))

p1 <- ggplot(m,
             aes(alf,value,group=variable,
                 colour=variable))+
  geom_line(size=1.2)+
  labs(title="punto de corte optimo para smv",
       x="cut - off",
       y="")
p1
```

Con la libreria lploty, el dato exacto de punto de corte con la metodologia de maximizacion de sensitividad-especificidad es 0.09.

### Enfoque de maximizacion del accuracy

```{r puntocorteoptimo_maxaccuracy, echo=FALSE}
max.accuracy <- performance(pred,measure = "acc")
plot(max.accuracy)

#Para ver el maximo, ya que en el grafico anterior no se ve bien
indice <- which.max(slot(max.accuracy,"y.values")[[1]])
acc <- slot(max.accuracy,"y.values")[[1]][indice]
cutoff <- slot(max.accuracy,"x.values")[[1]][indice]

print(c(accuracy=acc, cutoff=cutoff))
```

El punto de corte optimo con la metodologia de maximizacion del accuracy es 0.5069.

### Enfoque del pROC

```{r puntocorteoptimo_pROC, echo=FALSE}
prediccionescutoff <- attr(ajustados.mejor.modelo,
                           "probabilities")[,1]

curvaroc <- plot.roc(nuevadata$peso[entrenamiento],
                     as.vector(prediccionescutoff),
                     precent=TRUE,
                     ci=TRUE,
                     print.auc=TRUE,
                     threholds="best",
                     print.thres="best")
```

En este caso, el punto de corte optimo es 0.924.


En resumen, se tienen tres puntos de corte optimos: 0.09 (enfoque maximiacion sensitividad-especificidad), 0.5069 (enfoque de max del accuracy) y 0.924 (enfoque pROC).

### Evaluacion del modelo con los tres puntos de corte optimo calculados.

### Matriz de clasificacion - punto de corte optimo 1

```{r matriz_clasificacion_cutoff1}
threshold1=0.09
umbral1 <- as.numeric(threshold1)

table(attr(ajustados.mejor.modelo,
           "probabilities")[,1]>umbral1,
      nuevadata$peso[entrenamiento])

head(attr(ajustados.mejor.modelo,
          "probabilities"))

prediccionesthres <- attr(ajustados.mejor.modelo,
                           "probabilities")[,1]

prediccionesthres <- as.numeric(prediccionesthres)

predthres <- factor(ifelse(prediccionesthres>umbral1,1,0))


matrizpuntocorte1 <- data.frame(real=nuevadata$peso[entrenamiento],
                               predicho=predthres)

matrizpuntocorte1 <- matrizpuntocorte1 %>%
  mutate(predicho=recode_factor(predicho,
                                `0`="no.adecuado",
                                `1`="adecuado"))

confusionMatrix(matrizpuntocorte1$predicho,
                matrizpuntocorte1$real,
                positive = "adecuado")
```

### Matriz de clasificacion - punto de corte optimo 2

```{r matriz_clasificacion_cutoff2}
umbral2 <- as.numeric(cutoff)

table(attr(ajustados.mejor.modelo,
           "probabilities")[,1]>umbral2,
      nuevadata$peso[entrenamiento])

head(attr(ajustados.mejor.modelo,
          "probabilities"))

prediccionescut <- attr(ajustados.mejor.modelo,
                          "probabilities")[,1]

prediccionescut <- as.numeric(prediccionescut)

predcut <- factor(ifelse(prediccionescut>umbral2,1,0))


matrizpuntocorte2 <- data.frame(real=nuevadata$peso[entrenamiento],
                                predicho=predcut)

matrizpuntocorte2 <- matrizpuntocorte2 %>%
  mutate(predicho=recode_factor(predicho,
                                `0`="no.adecuado",
                                `1`="adecuado"))

confusionMatrix(matrizpuntocorte2$predicho,
                matrizpuntocorte2$real,
                positive = "adecuado")
```

### Matriz de clasificacion - punto de corte optimo 3

```{r matriz_clasificacion_cutoff3}
threshold2=0.924
umbral3 <- as.numeric(threshold2)

table(attr(ajustados.mejor.modelo,
           "probabilities")[,1]>umbral3,
      nuevadata$peso[entrenamiento])

head(attr(ajustados.mejor.modelo,
          "probabilities"))

prediccionescut <- attr(ajustados.mejor.modelo,
                        "probabilities")[,1]

prediccionescut <- as.numeric(prediccionescut)

predthres2 <- factor(ifelse(prediccionescut>umbral3,1,0))


matrizpuntocorte3 <- data.frame(real=nuevadata$peso[entrenamiento],
                                predicho=predthres2)

matrizpuntocorte3 <- matrizpuntocorte3 %>%
  mutate(predicho=recode_factor(predicho,
                                `0`="no.adecuado",
                                `1`="adecuado"))

confusionMatrix(matrizpuntocorte3$predicho,
                matrizpuntocorte3$real,
                positive = "adecuado")
```

A continuacion se mostrará el resumen de los principales resultados de las matrices de clasificación del modelo tuneado, y posteriormente con cada uno de los puntos de corte obtenidos.

```{r resumen_cutoffs, echo=FALSE}
indicador <- c("Punto de corte","Accuracy", "Sensitivity", "Specificity",
               "Pos Pred Value","Neg Pred Value")
modelotuneado <- c(0.5000, 0.9191, 0.9917, 0.2348, 0.9243, 0.7500)
corte_optimo1 <- c(0.0900, 0.9128, 1.0000, 0.0913, 0.9121, 1.0000)
corte_optimo2 <- c(0.5069, 0.9187, 0.9908, 0.2391, 0.9247, 0.7333)
corte_optimo3 <- c(0.9240, 0.7415, 0.7292, 0.8565, 0.9796, 0.2513)

resumen <- data.frame(indicador, modelotuneado, corte_optimo1, corte_optimo2,
                      corte_optimo3)

print(resumen)
```

El punto de corte optimo 3 (obtenido con pROC), si bien entrega el accuracy mas bajo, presenta un mejor balance entre la sensitividad y especificidad. Por tanto, si se busca un mejor balance entre estos indicadores (no en terminos de los unos o ceros de la muestra), se podria tomar como punto de corte optimo el tercero. Sin embargo, tomando como criterio el mayor accuracy, el punto de corte seleccionado seria con el que trabaja el modelo por defecto, que es un 0.5.

## Pronostico

A continuacion se realizara el pronostico para el modelo, en base a ciertos parametros seleccionados.

```{r pronostico1}
newdata1 <- data.frame(talla=47,
                      sem_gest=37,
                      sexo=1,
                      edad_mad=36,
                      sabe_leer=1,
                      con_pren=1,
                      edad2=1296)

pronostico1 <- predict(mejor.modelo,newdata1, probability = T)
pronostico1
```

El pronostico indica que, tomando en cuenta los datos ingresados, la probabilidad de que la niña recien nacida tenga buen peso es de 0.7969 (cercano al 80%).


Si se toma en cuenta el punto de corte óptimo de 0.5 (por defecto), esta niña seria clasificada como una niña con buen peso, ya que la probabilidad es más alta que el punto de corte.


Sin embargo, si se toma en cuenta el punto de corte de 0.924, el peso de la niña se sería pronosticado como peso inadecuado, lo cual no me parece razonable, ya que una talla de 47 cm está bastante aceptable, considerando que el rango de pesos de la base de datos esta entre los 38 cm y los 52 cm; asimismo, si bien las semanas de gestación son 37 (para el ejemplo), en ciertos casos los niños o niñas pueden nacer en estas semanas, si en consideración medica se tiene algunas variables que indican que es mejor que nazca a que se espere a la semana de gestación 40 (como puede ser, que la niña este enredada en el cordon umbilical, u otra complicación observada en los controles pre natales). Por otra parte, la edad de la madre de 36 no es alta y se observa que en controles prenatales tiene más que 7, lo que indica que la madre ha estado llevando los controles con el medico de forma regular.

Por tanto, se considera que es mas adecuado el punto de corte del 0.5, ya que el 0.924 resultaría muy estricto en términos de clasificación. Quizás un punto de corte entre 0.5 y 0.924 podría resultar más conveniente.


# SECCION C

## Remuestro con metodologia ROSE

```{r remuestreo}
table(nuevadata$peso[entrenamiento])

train_data <- nuevadata[entrenamiento, ]

roses  <- ROSE(peso ~.,
               data = train_data,seed = 1)$data

table(roses$peso)
```

## Estimacion de modelo SVM con remuestreo de ROSE

```{r SVM_ROSE}
modelo.rose <- tune(svm, peso ~ .,
                    data=roses,
                    ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 50)),
                    kernel = "linear",
                    scale=T,
                    probability = TRUE)

summary(modelo.rose)
mejor.modelo.rose <- modelo.rose$best.model
```

## Evaluacion del modelo con remuestreo ROSE

### Matriz de clasificacion

```{r Evaluacion_SVM_ROSE_MC}
ajustadosroses <- predict(mejor.modelo.rose,
                         roses, type="prob",probability=TRUE)

confusionMatrix(roses$peso,ajustadosroses,
                dnn = c("Actuales", "Predichos"),
                levels(ajustadosroses)[1])
```

Si bien el accuracy es mas bajo que los obtenidos con el modelo sin remuestroe, los indicadores de sensitividad y especificidad presentan un mejor balance, aunque por detras del modelo sin remuestreo y con punto de corte optimo definido con el enfoque pROC.

### Curva ROC y AUC

```{r Evaluacion_SVM_ROSE_ROCcurve}
predrose <- prediction(attr(ajustadosroses,
                            "probabilities")[,2],
                       roses$peso)

roc.curve(roses$peso, attr(ajustadosroses,
                           "probabilities")[,2], col="red")
```

Considerando que el AUC del modelo SVM sin remuestreo fue de 0.8548723, con un remuestreo, el area bajo la curva es menor y por tanto ese modelo, y no este, esta discriminando mejor la informacion.

## Grafico conjunto de curvas ROC

```{r Curvas_ROC}
roc.curve(roses$peso, attr(ajustadosroses,
                           "probabilities")[,2], col="red")
roc.curve(nuevadata$peso[entrenamiento],
          attr(ajustados.mejor.modelo,
               "probabilities")[,2],
          col="black",
          add.roc = T)
```

En el grafico anterior se puede observar que el modelo sin remuestreo clasifica de mejor forma las observaciones, aunque la diferencia no es muy importante.


A continuacion, se hallaran los puntos de corte optimos con base en el remuestreo de ROSE.

### Enfoque maximizacion sen-esp (ROSE)

```{r ROSE_cutoff1, warning=FALSE}
perf2 <- performance(predrose, "sens","spec") 
sen1 <- slot(perf2,"y.values"[[1]])
esp1 <- slot(perf2,"x.values"[[1]])
alf1 <- slot(perf2,"alpha.values"[[1]])

mat2 <- data.frame(alf1,sen1,esp1)

names(mat2)[1] <- "alf"
names(mat2)[2] <- "sen"
names(mat2)[3] <- "esp"

m2 <- melt(mat2,id=c("alf"))

p2 <- ggplot(m2,
             aes(alf,value,group=variable,
                 colour=variable))+
  geom_line(size=1.2)+
  labs(title="punto de corte optimo para ROSE",
       x="cut - off",
       y="")
p2
```

Con el uso de libreria plotly, se encuentra que el punto exacto de punto de corte es 0.4588

### Enfoque para el cut-off que maximiza el accuracy (ROSE)

```{r ROSE_cutoff2, warning=FALSE}
max.accuracy2 <- performance(predrose,measure = "acc")
plot(max.accuracy2)

indice2 <- which.max(slot(max.accuracy2,"y.values")[[1]])
acc2 <- slot(max.accuracy2,"y.values")[[1]][indice2]
cutoff2 <- slot(max.accuracy2,"x.values")[[1]][indice2]

print(c(accuracy=acc2, cutoff=cutoff2))
```

El cut-off es 0.4625

### Enfoque pROC (ROSE)

```{r ROSE_cutoff3, warning=FALSE}
prediccionescutoff2 <- attr(ajustadosroses,
                           "probabilities")[,1]

curvaroc2 <- plot.roc(roses$peso,
                     as.vector(prediccionescutoff2),
                     precent=TRUE,
                     ci=TRUE,
                     print.auc=TRUE,
                     threholds="best",
                     print.thres="best")
```

El punto de corte es 0.539.


Con los tres enfoques, el punto de corte optimo no difiere en gran medida.


## Evaluacion de matrices de clasificacion con puntos de corte
### Enfoque maximizacion sen-esp (ROSE)

```{r ROSE_MC_cutoff1, warning=FALSE}
threshold3=0.4588
umbral4 <- as.numeric(threshold3)

table(attr(ajustadosroses,
           "probabilities")[,1]>umbral4,
      roses$peso)

head(attr(ajustadosroses,
          "probabilities"))

prediccionesthres1 <- attr(ajustadosroses,
                          "probabilities")[,1]

prediccionesthres1 <- as.numeric(prediccionesthres1)

predthres3 <- factor(ifelse(prediccionesthres1>umbral4,1,0))


matrizpuntocorte4 <- data.frame(real=roses$peso,
                                predicho=predthres3)

matrizpuntocorte4 <- matrizpuntocorte4 %>%
  mutate(predicho=recode_factor(predicho,
                                `0`="no.adecuado",
                                `1`="adecuado"))

confusionMatrix(matrizpuntocorte4$predicho,
                matrizpuntocorte4$real,
                positive = levels(roses$peso)[1])
```

### Enfoque de maximizacion del accuracy (ROSE)

```{r ROSE_MC_cutoff2, warning=FALSE}
umbral5 <- as.numeric(cutoff2)

table(attr(ajustadosroses,
           "probabilities")[,1]>umbral5,
      roses$peso)

head(attr(ajustadosroses,
          "probabilities"))

prediccionescut2 <- attr(ajustadosroses,
                        "probabilities")[,1]

prediccionescut2 <- as.numeric(prediccionescut2)

predcut2 <- factor(ifelse(prediccionescut2>umbral5,1,0))


matrizpuntocorte5 <- data.frame(real=roses$peso,
                                predicho=predcut2)

matrizpuntocorte5 <- matrizpuntocorte5 %>%
  mutate(predicho=recode_factor(predicho,
                                `0`="no.adecuado",
                                `1`="adecuado"))

confusionMatrix(matrizpuntocorte5$predicho,
                matrizpuntocorte5$real,
                positive = "adecuado")
```

### Enfoque pROC (ROSE)

```{r ROSE_MC_cutoff3, warning=FALSE}
threshold4=0.539
umbral6 <- as.numeric(threshold4)

table(attr(ajustadosroses,
           "probabilities")[,1]>umbral6,
      roses$peso)

head(attr(ajustadosroses,
          "probabilities"))

prediccionescut3 <- attr(ajustadosroses,
                         "probabilities")[,1]

prediccionescut3 <- as.numeric(prediccionescut3)

predcut3 <- factor(ifelse(prediccionescut3>umbral6,1,0))


matrizpuntocorte6 <- data.frame(real=roses$peso,
                                predicho=predcut3)

matrizpuntocorte6 <- matrizpuntocorte6 %>%
  mutate(predicho=recode_factor(predicho,
                                `0`="no.adecuado",
                                `1`="adecuado"))

confusionMatrix(matrizpuntocorte6$predicho,
                matrizpuntocorte6$real,
                positive = "adecuado")
```

### Matriz resumen de puntos de corte con ROSE

```{r ROSE_resumen_cutoff, echo=FALSE}
indicador2 <- c("Punto_corte","Accuracy", "Sensitivity", "Specificity",
                "Pos Pred Value","Neg Pred Value")
modelo_rose <- c(0.5000, 0.7398, 0.7351, 0.7456, 0.7822, 0.6936)
corte_optimo_rose1 <- c(0.4588, 0.7381, 0.8279, 0.6406, 0.7146, 0.7739)
corte_optimo_rose2 <- c(0.4625, 0.7394, 0.8255, 0.6458, 0.7170, 0.7729)
corte_optimo_rose3 <- c(0.5390, 0.7473, 0.7518, 0.7424, 0.7603, 0.7334)

resumen_rose <- data.frame(indicador2, modelo_rose, corte_optimo_rose1,
                           corte_optimo_rose2,
                           corte_optimo_rose3)

print(resumen_rose)
```


El punto de corte optimo seleccionado es el 0.539 (corte_optimo_rose3), ya que presenta el mayor accuracy.

## Pronostico con ROSE

```{r ROSE_pronostico}
pronostico2 <- predict(mejor.modelo.rose,newdata1, probability = T)
pronostico2
```

COn el remuestreo de ROSE y los mismos datos que se tenian para el pronostico del modelo SVM sin remuestreo, la probabilidad de que la niña tenga un peso adecuado cae fuertemente y seria pronosticada como mal peso alancer.


Sin embargo, se observa que no existe mucha diferencia en los puntos de corte optimo con el remuestreo de ROSE, lo que si ocurria en el modelo SVM sin remuestreo.


A continuacion se asumiran nuevos datos para realizar un nuevo pronostico.

```{r ROSE_nuevo_pronostico}
newdata2 <- data.frame(talla=49,
                       sem_gest=37,
                       sexo=1,
                       edad_mad=36,
                       sabe_leer=1,
                       con_pren=1,
                       edad2=1296)

pronostico3 <- predict(mejor.modelo.rose,newdata2, probability = T)
pronostico3
```

Con estos nuevos datos y dado el punto de corte optimo seleccionado, que es 0.539, esta niña estaría clasificada como con un buen peso al nacer.


Con este ultimo ejercicio, lo que se pudo ver es que con el remuestro de ROSE, los datos son mas acidos, por decir de alguna manera, ya que para que un niño o niña sea considerada como buen peso, las variables explicativas deben ser mas adecuados en terminos de mejor talla, mayores semanas de gestacion, principalmente.

## Resultados finales

```{r cuadro_final, echo=FALSE}
modelo <- c("Optimo_SVM_sin_remuestreo", "Optimo_SVM_con_ROSE")
punto_corte <- c(0.5000, 0.5390)
pronostico_modelos_adecuado <- c(0.7969, 0.4422)
clasificacion_final <- c("Peso adecuado", "Peso no adecuado")

resumen_final <- data.frame(modelo, punto_corte, pronostico_modelos_adecuado,
                            clasificacion_final)

print(resumen_final)
```

Como conclusion final y producto del analisis realizado se resaltan los siguientes puntos:


Los resultados en terminos de probabilidades de ocurrencia de uno u otro evento, difieren fuertemente entre muestra balanceada y no balanceada.


Las matrices de clasificacion se modifican en gran medidad con los puntos de corte optimo seleccionados, tanto en el modelo SVM sin remuestreo como en el caso de remuestreo con ROSE.


Los puntos de corte optimo calculados con los tres enfoques, tienen resultados más heterogeneos cuando se tiene una muestra desbalanceada. En tanto, que con un remuestreo, el punto de corte optimo, bajo los tres enfoques, no varia grandemente.


El modelo SVM sin remuestreo y con remuestreo, generan curvas ROC diferentes. En este ejemplo, la curva ROC sin remuestreo es ligeramente superior, lo que indicaria que esta discriminando relativamente mejor que con la remuestra de ROSE.